{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import xgboost as xgb\n",
    "import joblib \n",
    "import numpy as np\n",
    "import dagshub\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\garam\\OneDrive\\Documents\\projet_ia\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\garam\\OneDrive\\Documents\\projet_ia\\.venv\\lib\\site-packages\\rich\\live.py:231: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=16ca7139-c4a2-452e-a8ba-e2f8f4903457&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=300e28dfb59288382c0b0f0d9cd6eef7ecf6d7c45471073efe1f3667347082e4\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Shurens\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Shurens\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Shurens/my-first-repo\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Shurens/my-first-repo\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Shurens/my-first-repo initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Shurens/my-first-repo initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dagshub.init(repo_owner='Shurens', repo_name='my-first-repo', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API endpoint URLs\n",
    "BASE_URL = \"http://127.0.0.1:8081\"  # Adjust the host and port if needed\n",
    "TOKEN_URL = f\"{BASE_URL}/token\"\n",
    "ALL_FILMS_URL = f\"{BASE_URL}/all_films\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Authenticate and get the token\n",
    "def get_token(username: str, password: str):\n",
    "    response = requests.post(TOKEN_URL, data={\"username\": username, \"password\": password})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"access_token\"]\n",
    "    else:\n",
    "        raise Exception(\"Authentication failed, check your credentials\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Fetch all films data using the token\n",
    "def fetch_all_films(token: str):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    response = requests.get(ALL_FILMS_URL, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        films_data = response.json()[\"films\"]\n",
    "        return pd.DataFrame(films_data)\n",
    "    else:\n",
    "        raise Exception(\"Failed to fetch films data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    # Étape 1: Préparation des données\n",
    "    X = df.drop(columns=[\"f_evaluation\"])  # Features except for the target\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(df[\"f_evaluation\"])\n",
    "    \n",
    "    # Étape 2: Séparation des données en train et test avec stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Vérification de la répartition des classes\n",
    "    print(\"Répartition des classes dans l'ensemble d'entraînement :\", \n",
    "          dict(zip(*np.unique(y_train, return_counts=True))))\n",
    "    print(\"Répartition des classes dans l'ensemble de test :\", \n",
    "          dict(zip(*np.unique(y_test, return_counts=True))))\n",
    "    \n",
    "    # Étape 3: Entraînement des modèles de classification\n",
    "    \n",
    "    # Modèle RandomForestClassifier\n",
    "    with mlflow.start_run(run_name=\"RandomForestClassifier\"):\n",
    "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred_rf = rf_model.predict(X_test)\n",
    "        accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "        precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "        recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "        f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "        \n",
    "        mlflow.log_metric(\"accuracy_rf\", accuracy_rf)\n",
    "        mlflow.log_metric(\"precision_rf\", precision_rf)\n",
    "        mlflow.log_metric(\"recall_rf\", recall_rf)\n",
    "        mlflow.log_metric(\"f1_rf\", f1_rf)\n",
    "        mlflow.sklearn.log_model(rf_model, \"random_forest_model\", registered_model_name=\"random_forest_model\")\n",
    "    \n",
    "    # Modèle XGBoostClassifier\n",
    "    with mlflow.start_run(run_name=\"XGBoostClassifier\"):\n",
    "        xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", n_estimators=100, random_state=42)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        y_pred_xgb = xgb_model.predict(X_test)\n",
    "        accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "        precision_xgb = precision_score(y_test, y_pred_xgb, average='weighted')\n",
    "        recall_xgb = recall_score(y_test, y_pred_xgb, average='weighted')\n",
    "        f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "        \n",
    "        mlflow.log_metric(\"accuracy_xgb\", accuracy_xgb)\n",
    "        mlflow.log_metric(\"precision_xgb\", precision_xgb)\n",
    "        mlflow.log_metric(\"recall_xgb\", recall_xgb)\n",
    "        mlflow.log_metric(\"f1_xgb\", f1_xgb)\n",
    "        mlflow.sklearn.log_model(xgb_model, \"xgboost_model\", registered_model_name=\"xgboost_model\")\n",
    "    \n",
    "    # Modèle LogisticRegression\n",
    "    with mlflow.start_run(run_name=\"LogisticRegression\"):\n",
    "        lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        y_pred_lr = lr_model.predict(X_test)\n",
    "        accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "        precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "        recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "        f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "        joblib.dump(label_encoder, \"label_encoder_films.joblib\")\n",
    "        mlflow.log_artifact(\"label_encoder_films.joblib\")\n",
    "        \n",
    "        mlflow.log_metric(\"accuracy_lr\", accuracy_lr)\n",
    "        mlflow.log_metric(\"precision_lr\", precision_lr)\n",
    "        mlflow.log_metric(\"recall_lr\", recall_lr)\n",
    "        mlflow.log_metric(\"f1_lr\", f1_lr)\n",
    "        mlflow.sklearn.log_model(lr_model, \"logistic_regression_model\", registered_model_name=\"logistic_regression_model\")\n",
    "    \n",
    "    # Affichage des résultats\n",
    "    print(f\"RandomForestClassifier - Accuracy: {accuracy_rf}, Precision: {precision_rf}, Recall: {recall_rf}, F1-score: {f1_rf}\")\n",
    "    print(f\"XGBoostClassifier - Accuracy: {accuracy_xgb}, Precision: {precision_xgb}, Recall: {recall_xgb}, F1-score: {f1_xgb}\")\n",
    "    print(f\"LogisticRegression - Accuracy: {accuracy_lr}, Precision: {precision_lr}, Recall: {recall_lr}, F1-score: {f1_lr}\")\n",
    "    \n",
    "    return {\n",
    "        \"RandomForestClassifier\": {\"accuracy\": accuracy_rf, \"precision\": precision_rf, \"recall\": recall_rf, \"f1\": f1_rf},\n",
    "        \"XGBoostClassifier\": {\"accuracy\": accuracy_xgb, \"precision\": precision_xgb, \"recall\": recall_xgb, \"f1\": f1_xgb},\n",
    "        \"LogisticRegression\": {\"accuracy\": accuracy_lr, \"precision\": precision_lr, \"recall\": recall_lr, \"f1\": f1_lr}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   f_budget  f_revenue  f_runtime  f_vote_count f_evaluation\n",
      "0  25000000  124272124        146          1910         bien\n",
      "1  45000000  788241776         89          5376         bien\n",
      "2  64000000   97571250         92           756         bien\n",
      "3  35000000  126216940        138          1310         bien\n",
      "4  15000000   56255142        148          3045         bien\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['evaluation'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# Preview the data to ensure it's loaded correctly\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Step 4: Train models on the data and log the results\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training complete. Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(df):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Étape 1: Préparation des données\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Features except for the target\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m      5\u001b[0m     y \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\garam\\OneDrive\\Documents\\projet_ia\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\garam\\OneDrive\\Documents\\projet_ia\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\garam\\OneDrive\\Documents\\projet_ia\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\garam\\OneDrive\\Documents\\projet_ia\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['evaluation'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "username = 'shuren'\n",
    "password = 'test'\n",
    "\n",
    "# Step 1: Get the token\n",
    "token = get_token(username, password)\n",
    "\n",
    "# Step 2: Fetch films data\n",
    "df = fetch_all_films(token)\n",
    "\n",
    "# Step 3: Convert the data to a Pandas DataFrame\n",
    "print(df.head())  # Preview the data to ensure it's loaded correctly\n",
    "\n",
    "# Step 4: Train models on the data and log the results\n",
    "results = train_model(df)\n",
    "print(\"Model training complete. Results:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "MLFLOW_URL = \"http://localhost:5000\"\n",
    "PROJECT_MODEL_NAME = \"logistic_regression_model\"\n",
    "MONITORER_DIR = \"mlflow\"\n",
    "experiment_name = \"logistic_regression_model\"\n",
    "\n",
    "def recuperer_nom_modeles(MLFLOW_URL, PROJECT_MODEL_NAME):\n",
    "    # Récupération des noms des modèles sur MLFLow\n",
    "    all_model_names=[]\n",
    "    model_registry_client = mlflow.tracking.MlflowClient(MLFLOW_URL)\n",
    "    model_versions = model_registry_client.search_model_versions(\"\")\n",
    "    model_names = set([mv.name for mv in model_versions])\n",
    "    for name in model_names:\n",
    "        if PROJECT_MODEL_NAME in name:\n",
    "            all_model_names.append(name)\n",
    "    return all_model_names[0], model_registry_client\n",
    "\n",
    "def charger_modele_et_artefacts(model_name, model_registry_client, MONITORER_DIR):\n",
    "    \"\"\"\n",
    "    Charge un modèle MLflow, ainsi que ses artefacts associés, et importe les modules Python associés.\n",
    "\n",
    "    Cette fonction récupère la version en production d'un modèle à partir du registre des modèles MLflow,\n",
    "    télécharge les artefacts associés, et importe dynamiquement tous les modules Python contenus dans les artefacts.\n",
    "    Les données de test et les prédictions associées au modèle sont également extraites.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Le nom du modèle à charger depuis le registre de modèles MLflow.\n",
    "        model_registry_client (mlflow.tracking.MlflowClient): Le client MLflow pour interagir avec le registre des modèles.\n",
    "        WORK_DIR (str): Le répertoire de travail où les artefacts du modèle seront téléchargés.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Un tuple contenant deux éléments :\n",
    "            \n",
    "    dict: Un dictionnaire avec les éléments suivants :\n",
    "    'model' (sklearn model): Le modèle MLflow chargé.\n",
    "    'run_id' (str): L'identifiant de la run associée au modèle.\n",
    "    'pickle' (str): Le chemin du fichier pickle des variables sauvegardées.\n",
    "    'X_test' (str): Les données de test utilisées lors de l'entraînement du modèle.\n",
    "    'y_test' (str): Les labels de test utilisés lors de l'entraînement du modèle.\n",
    "    'y_pred' (str): Les prédictions du modèle sur les données de test.\n",
    "    'rmse' (str or float): La valeur RMSE (Root Mean Square Error) du modèle, ou un message indiquant\n",
    "                            qu'aucune RMSE n'a été trouvée.\n",
    "    dict: Un dictionnaire des modules Python importés dynamiquement, avec les noms des modules comme clés.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: Si le répertoire spécifié pour les artefacts n'existe pas ou n'est pas un répertoire.\n",
    "        ImportError: Si l'importation des modules Python échoue.\n",
    "\n",
    "    \"\"\"\n",
    "    # Récupérer la version en production du modèle désigné\n",
    "    prod_model_version = model_registry_client.get_model_version_by_alias(model_name, \"production\")\n",
    "\n",
    "    # Charger le modèle MLflow et l'enregistrer dans un dictionnaire\n",
    "    model={}\n",
    "    model[\"model\"] = mlflow.sklearn.load_model(prod_model_version.source)\n",
    "    model[\"run_id\"] = prod_model_version.run_id\n",
    "\n",
    "    # Récupérer les artefacts du modèle\n",
    "    run = mlflow.get_run(model[\"run_id\"])\n",
    "    artifact_uri = run.info.artifact_uri\n",
    "\n",
    "    # # Supprimer le dossier des artefacts s'il existe déjà\n",
    "    # if os.path.exists(MONITORER_DIR+\"/model_artefacts/\") and os.path.isdir(MONITORER_DIR+\"/model_artefacts/\"):\n",
    "    #     shutil.rmtree(MONITORER_DIR+\"/model_artefacts/\")\n",
    "\n",
    "    # Télécharger les artefacts du modèle\n",
    "    artifact_folder = mlflow.artifacts.download_artifacts(artifact_uri, dst_path=MONITORER_DIR+\"/model_artefacts/\")\n",
    "    sys.path.append(artifact_folder)\n",
    "\n",
    "    # Télécharger les artefacts du modèle\n",
    "    artifact_folder = mlflow.artifacts.download_artifacts(artifact_uri, dst_path=os.path.join(MONITORER_DIR, \"model_artefacts\"))\n",
    "    sys.path.append(artifact_folder)\n",
    "\n",
    "    # Charger le LabelEncoder\n",
    "    label_encoder_path = os.path.join(artifact_folder, \"label_encoder_films.joblib\")\n",
    "    if os.path.exists(label_encoder_path):\n",
    "        model[\"label_encoder\"] = joblib.load(label_encoder_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Le fichier {label_encoder_path} n'a pas été trouvé.\")\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def tag_latest_model_as_production(MLFLOW_URL, experiment_name):\n",
    "    '''\n",
    "    Marque le modèle le plus récent comme étant le modèle en production.\n",
    "\n",
    "    Args:\n",
    "        mlflowURI (str): Adresse qui pointe vers MLFlow.\n",
    "        experiment_name (str): Nom du modèle dans le registre MLFlow.\n",
    "    '''\n",
    "    client = mlflow.tracking.MlflowClient(MLFLOW_URL)\n",
    "    registered_model = client.get_registered_model(experiment_name)\n",
    "\n",
    "    model_versions = client.search_model_versions(f\"name='{experiment_name}'\")\n",
    "    model_versions.sort(key=lambda x: x.last_updated_timestamp, reverse=True)\n",
    "\n",
    "    latest_model_version = model_versions[0] if model_versions else None\n",
    "    if latest_model_version:\n",
    "        client.set_registered_model_alias(registered_model.name, 'production', latest_model_version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_latest_model_as_production(MLFLOW_URL, \"logistic_regression_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom du modèle récupéré : logistic_regression_model\n"
     ]
    }
   ],
   "source": [
    "# Appeler la fonction pour récupérer le nom du modèle et le client MLflow\n",
    "try:\n",
    "    model_name, client = recuperer_nom_modeles(MLFLOW_URL, PROJECT_MODEL_NAME)\n",
    "    print(f\"Nom du modèle récupéré : {model_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la récupération du nom du modèle : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors du chargement du modèle et des artefacts : Le fichier c:\\Users\\Utilisateur\\Documents\\projet_ia\\bdd_films\\mlflow\\model_artefacts\\artifacts\\label_encoder.joblib n'a pas été trouvé.\n"
     ]
    }
   ],
   "source": [
    "# Définir le répertoire de surveillance (assurez-vous que le chemin existe)\n",
    "if not os.path.exists(MONITORER_DIR):\n",
    "    os.makedirs(MONITORER_DIR)\n",
    "\n",
    "# Appeler la fonction pour charger le modèle et ses artefacts\n",
    "try:\n",
    "    model_data = charger_modele_et_artefacts(model_name, client, MONITORER_DIR)\n",
    "    label_encoder = model_data[\"label_encoder\"]\n",
    "    loaded_model = model_data[\"model\"]\n",
    "    run_id = model_data[\"run_id\"]\n",
    "    print(f\"Modèle chargé avec succès. Run ID : {run_id}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du modèle et des artefacts : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction pour les données [[10550000 15500000      145       75]] : moyen\n"
     ]
    }
   ],
   "source": [
    "encoder = joblib.load(\"label_encoder_films.joblib\")\n",
    "model = mlflow.sklearn.load_model(\"mlflow/model_artefacts/artifacts/logistic_regression_model\") \n",
    "X_new = pd.DataFrame([[10550000, 15500000, 145, 75]], columns=[\"budget\", \"revenue\", \"runtime\", \"vote_count\"])\n",
    "try:\n",
    "    prediction_numeric = loaded_model.predict(X_new)\n",
    "    prediction_label = label_encoder.inverse_transform(prediction_numeric.astype(int))\n",
    "    print(f\"Prédiction pour les données {X_new.values} : {prediction_label[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la prédiction : {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
