{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import xgboost as xgb\n",
    "import joblib \n",
    "import numpy as np\n",
    "import dagshub\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAGSHUB_TOKEN = os.getenv('DAGSHUB_TOKEN')\n",
    "mlflow.set_tracking_uri(f'https://{DAGSHUB_TOKEN}@dagshub.com/Shurens/my-first-repo.mlflow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API endpoint URLs\n",
    "BASE_URL =  os.getenv('BASE_URL')  \n",
    "TOKEN_URL = f\"{BASE_URL}/token\"\n",
    "ALL_FILMS_URL = f\"{BASE_URL}/all_films\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Authenticate and get the token\n",
    "def get_token(username: str, password: str):\n",
    "    response = requests.post(TOKEN_URL, data={\"username\": username, \"password\": password})\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"access_token\"]\n",
    "    else:\n",
    "        raise Exception(\"Authentication failed, check your credentials\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Fetch all films data using the token\n",
    "def fetch_all_films(token: str):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\"\n",
    "    }\n",
    "    response = requests.get(ALL_FILMS_URL, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        films_data = response.json()[\"films\"]\n",
    "        return pd.DataFrame(films_data)\n",
    "    else:\n",
    "        raise Exception(\"Failed to fetch films data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    # Ã‰tape 1: PrÃ©paration des donnÃ©es\n",
    "    X = df.drop(columns=[\"f_evaluation\"])  # Features except for the target\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(df[\"f_evaluation\"])\n",
    "    \n",
    "    # Ã‰tape 2: SÃ©paration des donnÃ©es en train et test avec stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # VÃ©rification de la rÃ©partition des classes\n",
    "    print(\"RÃ©partition des classes dans l'ensemble d'entraÃ®nement :\", \n",
    "          dict(zip(*np.unique(y_train, return_counts=True))))\n",
    "    print(\"RÃ©partition des classes dans l'ensemble de test :\", \n",
    "          dict(zip(*np.unique(y_test, return_counts=True))))\n",
    "    \n",
    "    # Ã‰tape 3: EntraÃ®nement des modÃ¨les de classification\n",
    "    \n",
    "    # ModÃ¨le RandomForestClassifier\n",
    "    with mlflow.start_run(run_name=\"RandomForestClassifier\"):\n",
    "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred_rf = rf_model.predict(X_test)\n",
    "        accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "        precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "        recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "        f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "        \n",
    "        mlflow.log_metric(\"accuracy_rf\", accuracy_rf)\n",
    "        mlflow.log_metric(\"precision_rf\", precision_rf)\n",
    "        mlflow.log_metric(\"recall_rf\", recall_rf)\n",
    "        mlflow.log_metric(\"f1_rf\", f1_rf)\n",
    "        mlflow.log_artifact(\"label_encoder_films.joblib\")\n",
    "        mlflow.sklearn.log_model(rf_model, \"random_forest_model\", registered_model_name=\"random_forest_model\")\n",
    "    \n",
    "    # ModÃ¨le XGBoostClassifier\n",
    "    with mlflow.start_run(run_name=\"XGBoostClassifier\"):\n",
    "        xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", n_estimators=100, random_state=42)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        y_pred_xgb = xgb_model.predict(X_test)\n",
    "        accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "        precision_xgb = precision_score(y_test, y_pred_xgb, average='weighted')\n",
    "        recall_xgb = recall_score(y_test, y_pred_xgb, average='weighted')\n",
    "        f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "        \n",
    "        mlflow.log_metric(\"accuracy_xgb\", accuracy_xgb)\n",
    "        mlflow.log_metric(\"precision_xgb\", precision_xgb)\n",
    "        mlflow.log_metric(\"recall_xgb\", recall_xgb)\n",
    "        mlflow.log_metric(\"f1_xgb\", f1_xgb)\n",
    "        mlflow.sklearn.log_model(xgb_model, \"xgboost_model\", registered_model_name=\"xgboost_model\")\n",
    "    \n",
    "    # ModÃ¨le LogisticRegression\n",
    "    with mlflow.start_run(run_name=\"LogisticRegression\"):\n",
    "        lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        y_pred_lr = lr_model.predict(X_test)\n",
    "        accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "        precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
    "        recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
    "        f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "        joblib.dump(label_encoder, \"label_encoder_films.joblib\")\n",
    "        \n",
    "        mlflow.log_metric(\"accuracy_lr\", accuracy_lr)\n",
    "        mlflow.log_metric(\"precision_lr\", precision_lr)\n",
    "        mlflow.log_metric(\"recall_lr\", recall_lr)\n",
    "        mlflow.log_metric(\"f1_lr\", f1_lr)\n",
    "        mlflow.sklearn.log_model(lr_model, \"logistic_regression_model\", registered_model_name=\"logistic_regression_model\")\n",
    "    \n",
    "    # Affichage des rÃ©sultats\n",
    "    print(f\"RandomForestClassifier - Accuracy: {accuracy_rf}, Precision: {precision_rf}, Recall: {recall_rf}, F1-score: {f1_rf}\")\n",
    "    print(f\"XGBoostClassifier - Accuracy: {accuracy_xgb}, Precision: {precision_xgb}, Recall: {recall_xgb}, F1-score: {f1_xgb}\")\n",
    "    print(f\"LogisticRegression - Accuracy: {accuracy_lr}, Precision: {precision_lr}, Recall: {recall_lr}, F1-score: {f1_lr}\")\n",
    "    \n",
    "    return {\n",
    "        \"RandomForestClassifier\": {\"accuracy\": accuracy_rf, \"precision\": precision_rf, \"recall\": recall_rf, \"f1\": f1_rf},\n",
    "        \"XGBoostClassifier\": {\"accuracy\": accuracy_xgb, \"precision\": precision_xgb, \"recall\": recall_xgb, \"f1\": f1_xgb},\n",
    "        \"LogisticRegression\": {\"accuracy\": accuracy_lr, \"precision\": precision_lr, \"recall\": recall_lr, \"f1\": f1_lr}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   f_budget  f_revenue  f_runtime  f_vote_count f_evaluation\n",
      "0  25000000  124272124        146          1910         bien\n",
      "1  45000000  788241776         89          5376         bien\n",
      "2  64000000   97571250         92           756         bien\n",
      "3  35000000  126216940        138          1310         bien\n",
      "4  15000000   56255142        148          3045         bien\n",
      "RÃ©partition des classes dans l'ensemble d'entraÃ®nement : {np.int64(0): np.int64(151), np.int64(1): np.int64(152), np.int64(2): np.int64(152)}\n",
      "RÃ©partition des classes dans l'ensemble de test : {np.int64(0): np.int64(38), np.int64(1): np.int64(38), np.int64(2): np.int64(38)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/03 17:16:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'random_forest_model' already exists. Creating a new version of this model...\n",
      "2024/11/03 17:16:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: random_forest_model, version 3\n",
      "Created version '3' of model 'random_forest_model'.\n",
      "2024/11/03 17:16:17 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run RandomForestClassifier at: https://d0a87968a791705d505707f81cb9e16d8c269f9a@dagshub.com/Shurens/my-first-repo.mlflow/#/experiments/0/runs/36c90fa6113740db849a015d17c5d43c.\n",
      "2024/11/03 17:16:17 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://d0a87968a791705d505707f81cb9e16d8c269f9a@dagshub.com/Shurens/my-first-repo.mlflow/#/experiments/0.\n",
      "2024/11/03 17:16:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'xgboost_model' already exists. Creating a new version of this model...\n",
      "2024/11/03 17:16:31 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_model, version 3\n",
      "Created version '3' of model 'xgboost_model'.\n",
      "2024/11/03 17:16:32 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run XGBoostClassifier at: https://d0a87968a791705d505707f81cb9e16d8c269f9a@dagshub.com/Shurens/my-first-repo.mlflow/#/experiments/0/runs/1edaeb8d3b3841bb97fd434d22750019.\n",
      "2024/11/03 17:16:32 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://d0a87968a791705d505707f81cb9e16d8c269f9a@dagshub.com/Shurens/my-first-repo.mlflow/#/experiments/0.\n",
      "2024/11/03 17:16:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'logistic_regression_model' already exists. Creating a new version of this model...\n",
      "2024/11/03 17:16:48 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: logistic_regression_model, version 3\n",
      "Created version '3' of model 'logistic_regression_model'.\n",
      "2024/11/03 17:16:49 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run LogisticRegression at: https://d0a87968a791705d505707f81cb9e16d8c269f9a@dagshub.com/Shurens/my-first-repo.mlflow/#/experiments/0/runs/f517e164144c4b30b5b0765b2b645f40.\n",
      "2024/11/03 17:16:49 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: https://d0a87968a791705d505707f81cb9e16d8c269f9a@dagshub.com/Shurens/my-first-repo.mlflow/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier - Accuracy: 0.7456140350877193, Precision: 0.7447368421052633, Recall: 0.7456140350877193, F1-score: 0.7448176921861133\n",
      "XGBoostClassifier - Accuracy: 0.7105263157894737, Precision: 0.715013794282087, Recall: 0.7105263157894737, F1-score: 0.7122317253962823\n",
      "LogisticRegression - Accuracy: 0.543859649122807, Precision: 0.5190058479532164, Recall: 0.543859649122807, F1-score: 0.46940077466393254\n",
      "Model training complete. Results:\n",
      "{'RandomForestClassifier': {'accuracy': 0.7456140350877193, 'precision': np.float64(0.7447368421052633), 'recall': np.float64(0.7456140350877193), 'f1': np.float64(0.7448176921861133)}, 'XGBoostClassifier': {'accuracy': 0.7105263157894737, 'precision': np.float64(0.715013794282087), 'recall': np.float64(0.7105263157894737), 'f1': np.float64(0.7122317253962823)}, 'LogisticRegression': {'accuracy': 0.543859649122807, 'precision': np.float64(0.5190058479532164), 'recall': np.float64(0.543859649122807), 'f1': np.float64(0.46940077466393254)}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "username = 'shuren'\n",
    "password = 'test'\n",
    "\n",
    "# Step 1: Get the token\n",
    "token = get_token(username, password)\n",
    "\n",
    "# Step 2: Fetch films data\n",
    "df = fetch_all_films(token)\n",
    "\n",
    "# Step 3: Convert the data to a Pandas DataFrame\n",
    "print(df.head())  # Preview the data to ensure it's loaded correctly\n",
    "\n",
    "# Step 4: Train models on the data and log the results\n",
    "results = train_model(df)\n",
    "print(\"Model training complete. Results:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "# MLFLOW_URL = \"http://localhost:5000\"\n",
    "# PROJECT_MODEL_NAME = \"logistic_regression_model\"\n",
    "# MONITORER_DIR = \"mlflow\"\n",
    "# experiment_name = \"logistic_regression_model\"\n",
    "\n",
    "# def recuperer_nom_modeles(MLFLOW_URL, PROJECT_MODEL_NAME):\n",
    "#     # RÃ©cupÃ©ration des noms des modÃ¨les sur MLFLow\n",
    "#     all_model_names=[]\n",
    "#     model_registry_client = mlflow.tracking.MlflowClient(MLFLOW_URL)\n",
    "#     model_versions = model_registry_client.search_model_versions(\"\")\n",
    "#     model_names = set([mv.name for mv in model_versions])\n",
    "#     for name in model_names:\n",
    "#         if PROJECT_MODEL_NAME in name:\n",
    "#             all_model_names.append(name)\n",
    "#     return all_model_names[0], model_registry_client\n",
    "\n",
    "# def charger_modele_et_artefacts(model_name, model_registry_client, MONITORER_DIR):\n",
    "#     \"\"\"\n",
    "#     Charge un modÃ¨le MLflow, ainsi que ses artefacts associÃ©s, et importe les modules Python associÃ©s.\n",
    "\n",
    "#     Cette fonction rÃ©cupÃ¨re la version en production d'un modÃ¨le Ã  partir du registre des modÃ¨les MLflow,\n",
    "#     tÃ©lÃ©charge les artefacts associÃ©s, et importe dynamiquement tous les modules Python contenus dans les artefacts.\n",
    "#     Les donnÃ©es de test et les prÃ©dictions associÃ©es au modÃ¨le sont Ã©galement extraites.\n",
    "\n",
    "#     Args:\n",
    "#         model_name (str): Le nom du modÃ¨le Ã  charger depuis le registre de modÃ¨les MLflow.\n",
    "#         model_registry_client (mlflow.tracking.MlflowClient): Le client MLflow pour interagir avec le registre des modÃ¨les.\n",
    "#         WORK_DIR (str): Le rÃ©pertoire de travail oÃ¹ les artefacts du modÃ¨le seront tÃ©lÃ©chargÃ©s.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple: Un tuple contenant deux Ã©lÃ©ments :\n",
    "            \n",
    "#     dict: Un dictionnaire avec les Ã©lÃ©ments suivants :\n",
    "#     'model' (sklearn model): Le modÃ¨le MLflow chargÃ©.\n",
    "#     'run_id' (str): L'identifiant de la run associÃ©e au modÃ¨le.\n",
    "#     'pickle' (str): Le chemin du fichier pickle des variables sauvegardÃ©es.\n",
    "#     'X_test' (str): Les donnÃ©es de test utilisÃ©es lors de l'entraÃ®nement du modÃ¨le.\n",
    "#     'y_test' (str): Les labels de test utilisÃ©s lors de l'entraÃ®nement du modÃ¨le.\n",
    "#     'y_pred' (str): Les prÃ©dictions du modÃ¨le sur les donnÃ©es de test.\n",
    "#     'rmse' (str or float): La valeur RMSE (Root Mean Square Error) du modÃ¨le, ou un message indiquant\n",
    "#                             qu'aucune RMSE n'a Ã©tÃ© trouvÃ©e.\n",
    "#     dict: Un dictionnaire des modules Python importÃ©s dynamiquement, avec les noms des modules comme clÃ©s.\n",
    "\n",
    "#     Raises:\n",
    "#         FileNotFoundError: Si le rÃ©pertoire spÃ©cifiÃ© pour les artefacts n'existe pas ou n'est pas un rÃ©pertoire.\n",
    "#         ImportError: Si l'importation des modules Python Ã©choue.\n",
    "\n",
    "#     \"\"\"\n",
    "#     # RÃ©cupÃ©rer la version en production du modÃ¨le dÃ©signÃ©\n",
    "#     prod_model_version = model_registry_client.get_model_version_by_alias(model_name, \"production\")\n",
    "\n",
    "#     # Charger le modÃ¨le MLflow et l'enregistrer dans un dictionnaire\n",
    "#     model={}\n",
    "#     model[\"model\"] = mlflow.sklearn.load_model(prod_model_version.source)\n",
    "#     model[\"run_id\"] = prod_model_version.run_id\n",
    "\n",
    "#     # RÃ©cupÃ©rer les artefacts du modÃ¨le\n",
    "#     run = mlflow.get_run(model[\"run_id\"])\n",
    "#     artifact_uri = run.info.artifact_uri\n",
    "\n",
    "#     # # Supprimer le dossier des artefacts s'il existe dÃ©jÃ \n",
    "#     # if os.path.exists(MONITORER_DIR+\"/model_artefacts/\") and os.path.isdir(MONITORER_DIR+\"/model_artefacts/\"):\n",
    "#     #     shutil.rmtree(MONITORER_DIR+\"/model_artefacts/\")\n",
    "\n",
    "#     # TÃ©lÃ©charger les artefacts du modÃ¨le\n",
    "#     artifact_folder = mlflow.artifacts.download_artifacts(artifact_uri, dst_path=MONITORER_DIR+\"/model_artefacts/\")\n",
    "#     sys.path.append(artifact_folder)\n",
    "\n",
    "#     # TÃ©lÃ©charger les artefacts du modÃ¨le\n",
    "#     artifact_folder = mlflow.artifacts.download_artifacts(artifact_uri, dst_path=os.path.join(MONITORER_DIR, \"model_artefacts\"))\n",
    "#     sys.path.append(artifact_folder)\n",
    "\n",
    "#     # Charger le LabelEncoder\n",
    "#     label_encoder_path = os.path.join(artifact_folder, \"label_encoder_films.joblib\")\n",
    "#     if os.path.exists(label_encoder_path):\n",
    "#         model[\"label_encoder\"] = joblib.load(label_encoder_path)\n",
    "#     else:\n",
    "#         raise FileNotFoundError(f\"Le fichier {label_encoder_path} n'a pas Ã©tÃ© trouvÃ©.\")\n",
    "\n",
    "\n",
    "#     return model\n",
    "\n",
    "# def tag_latest_model_as_production(MLFLOW_URL, experiment_name):\n",
    "#     '''\n",
    "#     Marque le modÃ¨le le plus rÃ©cent comme Ã©tant le modÃ¨le en production.\n",
    "\n",
    "#     Args:\n",
    "#         mlflowURI (str): Adresse qui pointe vers MLFlow.\n",
    "#         experiment_name (str): Nom du modÃ¨le dans le registre MLFlow.\n",
    "#     '''\n",
    "#     client = mlflow.tracking.MlflowClient(MLFLOW_URL)\n",
    "#     registered_model = client.get_registered_model(experiment_name)\n",
    "\n",
    "#     model_versions = client.search_model_versions(f\"name='{experiment_name}'\")\n",
    "#     model_versions.sort(key=lambda x: x.last_updated_timestamp, reverse=True)\n",
    "\n",
    "#     latest_model_version = model_versions[0] if model_versions else None\n",
    "#     if latest_model_version:\n",
    "#         client.set_registered_model_alias(registered_model.name, 'production', latest_model_version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_latest_model_as_production(MLFLOW_URL, \"logistic_regression_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom du modÃ¨le rÃ©cupÃ©rÃ© : logistic_regression_model\n"
     ]
    }
   ],
   "source": [
    "# # Appeler la fonction pour rÃ©cupÃ©rer le nom du modÃ¨le et le client MLflow\n",
    "# try:\n",
    "#     model_name, client = recuperer_nom_modeles(MLFLOW_URL, PROJECT_MODEL_NAME)\n",
    "#     print(f\"Nom du modÃ¨le rÃ©cupÃ©rÃ© : {model_name}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Erreur lors de la rÃ©cupÃ©ration du nom du modÃ¨le : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur lors du chargement du modÃ¨le et des artefacts : Le fichier c:\\Users\\Utilisateur\\Documents\\projet_ia\\bdd_films\\mlflow\\model_artefacts\\artifacts\\label_encoder.joblib n'a pas Ã©tÃ© trouvÃ©.\n"
     ]
    }
   ],
   "source": [
    "# # DÃ©finir le rÃ©pertoire de surveillance (assurez-vous que le chemin existe)\n",
    "# if not os.path.exists(MONITORER_DIR):\n",
    "#     os.makedirs(MONITORER_DIR)\n",
    "\n",
    "# # Appeler la fonction pour charger le modÃ¨le et ses artefacts\n",
    "# try:\n",
    "#     model_data = charger_modele_et_artefacts(model_name, client, MONITORER_DIR)\n",
    "#     label_encoder = model_data[\"label_encoder\"]\n",
    "#     loaded_model = model_data[\"model\"]\n",
    "#     run_id = model_data[\"run_id\"]\n",
    "#     print(f\"ModÃ¨le chargÃ© avec succÃ¨s. Run ID : {run_id}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Erreur lors du chargement du modÃ¨le et des artefacts : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrÃ©diction pour les donnÃ©es [[10550000 15500000      145       75]] : moyen\n"
     ]
    }
   ],
   "source": [
    "# encoder = joblib.load(\"label_encoder_films.joblib\")\n",
    "# model = mlflow.sklearn.load_model(\"mlflow/model_artefacts/artifacts/logistic_regression_model\") \n",
    "# X_new = pd.DataFrame([[10550000, 15500000, 145, 75]], columns=[\"budget\", \"revenue\", \"runtime\", \"vote_count\"])\n",
    "# try:\n",
    "#     prediction_numeric = loaded_model.predict(X_new)\n",
    "#     prediction_label = label_encoder.inverse_transform(prediction_numeric.astype(int))\n",
    "#     print(f\"PrÃ©diction pour les donnÃ©es {X_new.values} : {prediction_label[0]}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Erreur lors de la prÃ©diction : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PrÃ©diction pour les donnÃ©es [[  5500000 141195658       130       562]] : moyen\n"
     ]
    }
   ],
   "source": [
    "# import mlflow\n",
    "# import joblib \n",
    "# import pandas as pd\n",
    "\n",
    "# # Load the model\n",
    "# logged_model = 'runs:/4c15cf97a8124539ad82139f53ba5fbe/random_forest_model'\n",
    "# encoder = joblib.load(\"label_encoder_films.joblib\")\n",
    "\n",
    "# # Load model as a PyFuncModel.\n",
    "# loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# # Create a DataFrame for prediction input\n",
    "# X_new = pd.DataFrame([[5500000, 141195658, 130, 562 ]], columns=[\"f_budget\", \"f_revenue\", \"f_runtime\", \"f_vote_count\"])\n",
    "\n",
    "# # Predict and assign the output to a variable\n",
    "# prediction_numeric = loaded_model.predict(X_new)\n",
    "\n",
    "# # Transform the numeric prediction to a label\n",
    "# prediction_label = encoder.inverse_transform(prediction_numeric.astype(int))\n",
    "\n",
    "# # Print the result\n",
    "# print(f\"PrÃ©diction pour les donnÃ©es {X_new.values} : {prediction_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model validation successful: 8 correct predictions.\n",
      "                           f_original_title f_evaluation predicted_evaluation\n",
      "0  From Dusk Till Dawn 2: Texas Blood Money     mediocre                 bien\n",
      "1                                      Seed     mediocre             mediocre\n",
      "2                             Spirited Away         bien                 bien\n",
      "3           The Good, the Bad and the Ugly          bien                 bien\n",
      "4                            Precious Cargo        moyen                moyen\n",
      "5                                   Morbius        moyen                 bien\n",
      "6                                Coriolanus        moyen                moyen\n",
      "7                                    Volver        moyen                moyen\n",
      "8                              The Runaways        moyen                moyen\n",
      "9                               Thunderball        moyen                moyen\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import mlflow\n",
    "# import joblib\n",
    "\n",
    "# # Load the model and the encoder\n",
    "# logged_model = 'runs:/4c15cf97a8124539ad82139f53ba5fbe/random_forest_model'\n",
    "# encoder = joblib.load(\"label_encoder_films.joblib\")\n",
    "# loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# # Load the test data from CSV (assuming it's saved as 'test_data.csv')\n",
    "# test_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# # Prepare the features for prediction\n",
    "# X_test = test_data[[\"f_budget\", \"f_revenue\", \"f_runtime\", \"f_vote_count\"]]\n",
    "\n",
    "# # Make predictions\n",
    "# predictions_numeric = loaded_model.predict(X_test)\n",
    "\n",
    "# # Convert numeric predictions to labels\n",
    "# predictions_label = encoder.inverse_transform(predictions_numeric.astype(int))\n",
    "\n",
    "# # Add the predictions to the DataFrame for comparison\n",
    "# test_data['predicted_evaluation'] = predictions_label\n",
    "\n",
    "# # Check how many predictions match the actual values\n",
    "# correct_predictions = (test_data['predicted_evaluation'] == test_data['f_evaluation']).sum()\n",
    "\n",
    "# # Validate the model with a threshold of 7 correct answers\n",
    "# if correct_predictions >= 7:\n",
    "#     print(f\"Model validation successful: {correct_predictions} correct predictions.\")\n",
    "# else:\n",
    "#     print(f\"Model validation failed: {correct_predictions} correct predictions.\")\n",
    "\n",
    "# # Optionally, print the DataFrame to see the comparison\n",
    "# print(test_data[['f_original_title', 'f_evaluation', 'predicted_evaluation']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
